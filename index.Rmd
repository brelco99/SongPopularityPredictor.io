---
title: "Properties of the Perfect Popular Song (By Genre)"
author: "Brooke Conley"
date: "5/17/2020"
output: 
  html_document:
    theme: darkly
---
![Inspired by Spotify](spoty.png)
</center> [Source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fdaynespromotions.com%2Fhow-to-grow-your-spotify-following%2F&psig=AOvVaw0cI4rQlicX8y-V_GYedhBD&ust=1589937724698000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPCgkt7hvukCFQAAAAAdAAAAABAD)

<style>
pre.darkbkgrnd { background-color:"#222222"; }
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("lubridate")
library("dplyr")
library("caret")
library("rvest")
library("corrplot")
library("ggdark")
library("ggplot2")
library("manipulate")
library("RColorBrewer")
library("randomForest")
library("scales")
library("data.table")
```



## Introduction

The way we listen to music today is very different from the way we listened to music 50 years ago. We have substantially more freedom when it comes to selecting which songs we want to listen to and when, and this fact, among many others, has influenced the way that music is produced. Historically, people listened to what was on the radio. While records and record players were commonplace in the 60s and 70s, a lot of the time these records served as personal copies of what was playing on the radio (or what had been, in years prior). People tend to prefer music they are familiar with, and with the huge surge in FM radio's popularity circa the 1960s and 70s came lots of familiarity with the musicians who managed to get radio stations to play their music. This contributed to the rise of hugely popular record labels that dominated the industry and left little room for competition. Today, listeners have more options; there are 1.2 million artists on Spotify alone. This means that getting a song on the radio isn't necessarily enough to bring it the type of success it would have found in decades prior. Nowadays, producers have started to try and boil popular music down to an algorithm; here is an interesting article about how AI is changing the music scene: 
https://www.theverge.com/2018/8/31/17777008/artificial-intelligence-taryn-southern-amper-music

The Times They Are a-Changin', to say the least. But what does this mean for us? Can you really boil music taste, which is seemingly so complex and personal, down to an algorithm? Is there a formula that can produce the perfect song for you? Not yet. However, they are becoming better and better at predicting which songs will appeal to the masses. Today, we are going to look at which features are most closely correlated with the popularity of a song for each of four of the most popular genres; pop, rock, rap, and country. 

This dataset was the ideal choice for conducting this experiment because of both its size and its range. The creator used the Spotify Web API to gather data on "approximately 10,000 [songs] per genre," which is plenty for our purposes. 
The dataset can be found here - https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db 

The R Markdown file can be found here -
https://brelco99.github.io/FINALPROJECT.Rmd

The track properties we will be using today are genre, tempo, duration, and loudness, along with some less quantitative measures like energy, danceability, liveness, valence, acousticness, speechiness, and popularity, calculated by Spotify using their own metrics. 


## The Question: What do listeners want to hear, and how does it vary by genre? 
Can we predict the popularity of a song based on the metrics provided by Spotify? And is this consistent across genres?

## Data Curation
First, we import the song data. For sake of ease, we remove songs with any missing attributes from the dataframe. Then, using the unique track_id of each song, we check for (and remove) duplicate listings. This is the only place we will make use of track_id, so we remove that column from the dataframe. We then remove the time_signature column, leaving us with only attributes that can be normalized in a meaningful manner. Next, we subset to include only the genres of interest, which are country, rock, rap, and pop. Rearranging the dataframe so that char attributes are in the first columns and numeric attributes are in the rest makes it easier to grab either of those subsets when we need to.
```{r, warning=FALSE, message=FALSE}
#Read in data
tunes_tab <- read_csv("ultimate-spotify-tracks-db/SpotifyFeatures.csv")
#Remove any incomplete data
tunes_tab <- na.omit(tunes_tab)
#Remove any duplicate song listings
tunes_tab <- tunes_tab[!duplicated(tunes_tab$track_id),]
#Remove track ID column
tunes_tab$track_id <- NULL
#Remove time signature column (would not produce meaningful correlation coefficient due to discrete nature)
tunes_tab$time_signature <- NULL
#Remove unwanted genres
tunes_tab <- tunes_tab[((tunes_tab$genre == 'Country') | (tunes_tab$genre == 'Rock') |(tunes_tab$genre == 'Rap') |(tunes_tab$genre == 'Pop')),]
#Rearrange dataframe to separate char and double attributes
tunes_tab <- tunes_tab[,c(1, 2, 3, 10, 13, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16)]
#Show a tibble of the new dataframe 
tunes_tab

```
We could also take out the artist and track name variables but it is not necessary quite yet.


## Parsing and Data Management

Next, we normalize each of the numeric attributes other than popularity. This will help us determine the correlation between the attributes. We can then take a peak at the summary stats for each feature (again, other than popularity).
```{r, warning=FALSE, message=FALSE}
#Normalize the numeric attributes
stand_tunes <- as.data.frame(scale(tunes_tab[7:16]))
non_numeric <- tunes_tab[1:6]
#Update tunes_tab with normalized attributes
tunes_tab <- cbind(non_numeric, stand_tunes)
pop_bin <- tunes_tab$popularity
#Bind this new column to the dataframe
tunes_tab <- cbind(tunes_tab, pop_bin)
#View summary data of attributes
summary(stand_tunes)
```


## Exploratory Data Analysis

Now it is time to analyze what we have so far. First, we will look at overall trends with respect to each feature, across all four genres. 

```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[7:16]
plot <- tunes_tab %>%
  select(c(feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density( alpha = 0.5) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Overall Feature Density',
       x = '', y = 'density') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```

Next, we are going to spice it up a little by showing how each individual genre contributes to the above curves:
```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[7:16]
plot <- tunes_tab %>%
  select(c('genre', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density(aes(color = genre), alpha = 0.5) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Feature Density by Genre',
       x = '', y = 'density') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```
Much prettier. Now, looking at these graphs, we can see a few of the distinct features of each genre. Only a few trends stand out in particular in this visual. Rap tends to score lower on energy and slightly lower on valence than the other three, but also tends to be rated as more danceable. Country music tends to be the most neutral in terms of danceability of the group. Another way to look at this data (arguably the easier-to-read way) is by using a correlation plot:
```{r, fig.width=10, fig.height=12, warning=FALSE, message=FALSE}
library(ggcorrplot)

feature_names <- names(tunes_tab)[6:16]
plot <- tunes_tab %>%
  select(feature_names) %>%
  scale() %>%
  cor() %>%
   ggcorrplot(type = "lower", hc.order = TRUE,
         col = brewer.pal(n = 2, name = "RdBu"))  + dark_theme_gray() 
plot + theme(axis.text.x = element_text(angle = 90, hjust = 1),
             rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(colour = "#222222"),axis.title.x = element_blank(), axis.title.y = element_blank())



```

This is more interesting to us because it lets us see a simpler representation of the correlations, and strong correlations mean easier predicting. There is unfortunately not a lot of strong correlation. However, we can see from this plot that there is a relatively strong positive correlation between energy and loudness, and a relatively strong negative correlation between acousticness and both energy and loudness. Energy, loudness, danceability, and valence are all positively correlated, while instrumentalness is negatively correlated with energy and loudness. Popularity is most strongly correlated with energy, loudness, and danceability. Interesting! 

We can plot the relationships between popularity and danceability, energy, and loudness:

```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[c(8, 10, 13)]
plot <- tunes_tab %>%
  select(c('genre', 'popularity', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value, y=popularity, color = genre)) +
  geom_smooth( alpha = 0.5, se = FALSE)+
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Danceability, Energy, and Loudness vs Popularity',
       x = '', y = 'Popularity') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```

We can see here that increased danceability tends to increased popularity for rap, pop, and rock songs, but not country. Increasing energy tends to decrease popularity for rock songs, but only very slightly. There is not much of a relationship between energy and the other genres. Finally, as loudness increases, pop popularity increases notably, country popularity increases slightly, and the other two do not change much in either direction. It is clear that the genres each have distinct features that correlate with popularity (although country music has the weakest correlations of the lot).

Now that we know that each genre has different features correlating with its popularity index, we can see which ones and to what scale by using Random Forest Modeling.


## Hypothesis Testing and Machine Learning

Finally, it is time to build the model. Can we predict which songs will be rated with a popularity score of 70 or above for each genre, simply by feature analysis? Let's see:



First, we read all of the data for one genre into the song_features dataframe. This is a function so we can reuse it for modeling the other genres. Pass in the genre of interest and receive a dataframe with 12 numeric variables in return. It is a good idea to try and omit empty entries whenever you are subsetting data. 
```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
features_by_genre <- function(genre) {
genre_data <- tunes_tab[tunes_tab$genre == genre,]
song_features <- genre_data %>%
  select(
    popularity,
    pop_bin,
    acousticness,
    danceability,
    duration_ms,
    energy,
    instrumentalness,
    liveness,
    loudness,
    speechiness,
    tempo,
    valence
  ) %>% 
  na.omit()
song_features
}
```

Now we have our dataframe. We will start by creating a random forest model for predicting rap song popularity outcomes.

### Rap 
Here, we call the above function to get our rap-only dataframe. Then we plan to use pop_bin, which was previously a copy of popularity and varied substantially between genres, so we scale it to each one individually. We turn pop_bin into a column of 0s and 1s, depending on whether or not they were in the top 25% most popular songs of the genre in the dataset. Finally, we select pop_bin as our factor for the model.
```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
#Pull out genre data
song_features <- features_by_genre('Rap')
#Scale popularity to individual genre
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
#Input 0 or 1 to factor column depending on popularity
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
#Select pop_bin as factor
song_features$pop_bin <-as.factor(song_features$pop_bin)
#Remove original popularity column
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE}
bestmtry <- tuneRF(song_features[,-10], song_features[,10], stepFactor=1.5, improve=1e-5, ntree=500)
print(bestmtry)
```

```{r, warning=FALSE, message=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- as.data.frame(song_features[train,])
valid_set <- as.data.frame(song_features[-train,])
```


We need to check if our data is imbalanced or not. Imbalanced classification problems typically are split 10% and 90%, and for both our testing and training data the distribution is closer to 23% and 77%. We only do this once, because there is no reason for collection methods to vary by genre.

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
setDT(train_set)[,.N/nrow(train_set),pop_bin]
```

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
setDT(valid_set)[,.N/nrow(valid_set),pop_bin]
```


Now we create the model. 
```{r, warning=FALSE, message=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 2, ntree = 500)
model
```

```{r, warning=FALSE, message=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

### Rock

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE, echo=FALSE}
song_features <- features_by_genre('Rock')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 4, ntree = 500)
model
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```


### Country

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE, echo=FALSE}
song_features <- features_by_genre('Country')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 3, ntree = 500)
model
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```


### Pop

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE, echo=FALSE}
song_features <- features_by_genre('Pop')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 3, ntree = 500)
model
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

## Insights

The model had a similar error rate in predicting popularity all four genres; the pop model had an error rate of 20.82%, the country model 19.27%, the rock model 22.91%, and the rap model 20.12%. This is pretty decent performance, given that the random forest function was used with mostly default settings and we did not tune hyperparameters. We can see that dancibility, loudness, and energy are the most reliable indicators of popularity for pop songs; energy, speechiness, and loudness were the best indicators for country songs; energy, loudness, and valence for rock were the best indicators for rock songs; and energy, loudness, and speechiness are the most reliable indicators for rap songs. 
In conclusion, this experiment does demonstrate that there is definitely the potential to optimize song popularity outcomes by tuning individual features.









