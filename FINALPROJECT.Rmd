---
title: "Properties of the Perfect Popular Song (By Genre)"
author: "Brooke Conley"
date: "5/17/2020"
output: 
  html_document:
    theme: darkly
---
![Inspired by Spotify](spoty.png)
</center> [Source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fdaynespromotions.com%2Fhow-to-grow-your-spotify-following%2F&psig=AOvVaw0cI4rQlicX8y-V_GYedhBD&ust=1589937724698000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPCgkt7hvukCFQAAAAAdAAAAABAD)

<style>
pre.darkbkgrnd { background-color:"#222222"; }
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("lubridate")
library("dplyr")
library("caret")
library("rvest")
library("corrplot")
library("ggdark")
library("ggplot2")
library("manipulate")
library("RColorBrewer")
library("randomForest")
library("scales")
```



## Introduction

The way we listen to music today is very different from the way we listened to music 50 years ago. We have substantially more freedom when it comes to selecting which songs we want to listen to and when, and this fact, among many others, has influenced the way that music is produced. Historically, people listened to what was on the radio. While records and record players were commonplace in the 60s and 70s, a lot of the time these records served as personal copies of what was playing on the radio (or what had been, in years prior). People tend to prefer music they are familiar with, and with the huge surge in FM radio's popularity circa the 1960s and 70s came lots of familiarity with the musicians who managed to get radio stations to play their music. This contributed to the rise of hugely popular record labels that dominated the industry and left little room for competition. Today, listeners have more options; there are 1.2 million artists on Spotify alone. This means that getting a song on the radio isn't necessarily enough to bring it the type of success it would have found in decades prior. Nowadays, producers have started to try and boil popular music down to an algorithm; here is an interesting article about how AI is changing the music scene: 
https://www.theverge.com/2018/8/31/17777008/artificial-intelligence-taryn-southern-amper-music

The Times They Are a-Changin', to say the least. But what does this mean for us? Can you really boil music taste, which is seemingly so complex and personal, down to an algorithm? Is there a formula that can produce the perfect song for you? Not yet. However, they are becoming better and better at predicting which songs will appeal to the masses. Today, we are going to look at which features are most closely correlated with the popularity of a song for each of four of the most popular genres; pop, rock, rap, and country. 

This dataset was the ideal choice for conducting this experiment because of both its size and its range. The creator used the Spotify Web API to gather data on "approximately 10,000 [songs] per genre," which is plenty for our purposes. 
The dataset can be found here - https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db 

The R Markdown file can be found here -
https://brelco99.github.io/FINALPROJECT.Rmd

The track properties we will be using today are genre, tempo, duration, and loudness, along with some less quantitative measures like energy, danceability, liveness, valence, acousticness, speechiness, and popularity, calculated by Spotify using their own metrics. 


## The Question: What do listeners want to hear, and how does it vary by genre? 
Can we predict the popularity of a song based on the metrics provided by Spotify? And is this consistent across genres?

## Data Curation
First, we import the song data. For sake of ease, we remove songs with any missing attributes from the dataframe. Then, using the unique track_id of each song, we check for (and remove) duplicate listings. This is the only place we will make use of track_id, so we remove that column from the dataframe. Finally, we remove the time_signature column, leaving us with only attributes that can be normalized in a meaningful manner. Next, we subset to include only the genres of interest, which are country, rock, rap, and pop. Rearranging the dataframe so that char attributes are in the first columns and numeric attributes are in the rest makes it easier to grab either of those subsets when we need to.
```{r, warning=FALSE, message=FALSE}
#Read in data
tunes_tab <- read_csv("ultimate-spotify-tracks-db/SpotifyFeatures.csv")
#Remove any incomplete data
tunes_tab <- na.omit(tunes_tab)
#Remove any duplicate song listings
tunes_tab <- tunes_tab[!duplicated(tunes_tab$track_id),]
#Remove track ID column
tunes_tab$track_id <- NULL
#Remove time signature column 
tunes_tab$time_signature <- NULL
#Remove unwanted genres
tunes_tab <- tunes_tab[((tunes_tab$genre == 'Country') | (tunes_tab$genre == 'Rock') |(tunes_tab$genre == 'Rap') |(tunes_tab$genre == 'Pop')),]
#Rearrange dataframe to separate char and double attributes
tunes_tab <- tunes_tab[,c(1, 2, 3, 10, 13, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16)]
#Show a tibble of the new dataframe 
tunes_tab

```



## Parsing and Data Management

Next, we normalize each of the numeric attributes other than popularity. This will help us determine the correlation between the attributes.
```{r, warning=FALSE, message=FALSE}
#Normalize the numeric attributes
stand_tunes <- as.data.frame(scale(tunes_tab[7:16]))
non_numeric <- tunes_tab[1:6]
#Update tunes_tab with normalized attributes
tunes_tab <- cbind(non_numeric, stand_tunes)
pop_bin <- tunes_tab$popularity
#Bind this new column to the dataframe
tunes_tab <- cbind(tunes_tab, pop_bin)
#View summary data of attributes
summary(stand_tunes)
```


## Exploratory Data Analysis

Now it is time to analyze what we have so far. First, we will look at overall trends with respect to each feature.


```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[7:16]
plot <- tunes_tab %>%
  select(c('genre', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density(aes(color = genre), alpha = 0.5) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Feature Density by Genre',
       x = '', y = 'density') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```
Popularity appears to increase most significantly with energy and loudness. Danceability shows a similar but subtler trend. Let's look more closely at these three, using a linear model to look at how these three features relate to popularity.

```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[c(8, 10, 13)]
plot <- tunes_tab %>%
  select(c('genre', 'popularity', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value, y=popularity, color = genre)) +
  geom_smooth( alpha = 0.5, se = FALSE)+
  facet_wrap(~name, ncol = 1, scales = 'free') +
  labs(title = 'Danceability, Energy, and Loudness vs Popularity',
       x = '', y = 'Popularity') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```

We can see here that rap music tends to be more popular when it is above average in terms of danceability, but country, rock, and pop seem to fare best when danceability levels are kept around average. Rap music tends to be more popular when its energy is average to below average, whereas  country, rock, and pop all do better with above average enery levels. The last graph shows us that people tend to prefer the same levels of loudness regardless of genre, with that level being about the average of all songs in the dataframe. Next, we use a correlation plot to see how the relationships for all features in the dataframe.  

```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
library(ggcorrplot)

feature_names <- names(tunes_tab)[6:16]
plot <- tunes_tab %>%
  select(feature_names) %>%
  scale() %>%
  cor() %>%
   ggcorrplot(type = "lower", hc.order = TRUE,
         col = brewer.pal(n = 2, name = "RdBu"))  + dark_theme_gray() 
plot + theme(axis.text.x = element_text(angle = 90, hjust = 1),
             rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(colour = "#222222"),axis.title.x = element_blank(), axis.title.y = element_blank())



```
We can see from this plot that there is a strong positive correlation between energy and loudness, and a strong negative correlation between acousticness and both energy and loudness. Energy, loudness, danceability, and valence are all positively correlated, while instrumentalness is negatively correlated with energy and loudness. Popularity is most strongly correlated with energy, loudness, and danceability.





## Hypothesis Testing and Machine Learning

Finally, it is time to build the model. Can we predict which songs will be rated with a popularity score of 70 or above, simply just by analyzing features? Let's see:


```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
features_by_genre <- function(genre) {
genre_data <- tunes_tab[tunes_tab$genre == genre,]
song_features <- genre_data %>%
  select(
    popularity,
    pop_bin,
    acousticness,
    danceability,
    duration_ms,
    energy,
    instrumentalness,
    liveness,
    loudness,
    speechiness,
    tempo,
    valence
  ) %>% 
  na.omit()
song_features
}
```


```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
song_features <- features_by_genre('Rap')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```



```{r, warning=FALSE, message=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification)
model
```

```{r, warning=FALSE, message=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

Rock
```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
song_features <- features_by_genre('Rock')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```



```{r, warning=FALSE, message=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification)
model
```

```{r, warning=FALSE, message=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
song_features <- features_by_genre('Country')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```



```{r, warning=FALSE, message=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification)
model
```

```{r, warning=FALSE, message=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
song_features <- features_by_genre('Pop')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```



```{r, warning=FALSE, message=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification)
model
```

```{r, warning=FALSE, message=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

## Insights

The model had a similar error rate in predicting popularity all four genres; the pop model had an error rate of 20.82%, the country model 19.27%, the rock model 22.91%, and the rap model 20.12%. This is pretty decent performance, given that the random forest function was used with mostly default settings and we did not tune hyperparameters.  We can see that dancibility, loudness, and energy are the most reliable indicators of popularity for pop songs; energy, speechiness, and loudness were the best indicators for country songs; energy, loudness, and valence for rock were the best indicators for rock songs; and energy, loudness, and speechiness are the most reliable indicators for rap songs. 
In conclusion, this experiment does demonstrate that there is definitely the potential to optimize song popularity outcomes by tuning individual features.









