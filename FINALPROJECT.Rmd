---
title: "Properties of the Perfect Popular Song (By Genre)"
author: "Brooke Conley"
output: 
  html_document:
    theme: darkly
---
![Inspired by Spotify](spoty.png)
</center> [Source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fdaynespromotions.com%2Fhow-to-grow-your-spotify-following%2F&psig=AOvVaw0cI4rQlicX8y-V_GYedhBD&ust=1589937724698000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCPCgkt7hvukCFQAAAAAdAAAAABAD)



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tidyverse")
library("lubridate")
library("dplyr")
library("caret")
library("rvest")
library("corrplot")
library("ggdark")
library("ggplot2")
library("manipulate")
library("RColorBrewer")
library("randomForest")
library("scales")
library("data.table")
library("ggcorrplot")
```



## Introduction

The way we listen to music today is very different from the way we listened to music 50 years ago. We have substantially more freedom when it comes to selecting which songs we want to listen to and when, and this fact, among many others, has influenced the way that music is produced. Historically, people listened to what was on the radio. While records and record players were commonplace in the 60s and 70s, a lot of the time these records served as personal copies of what was playing on the radio (or what had been, in years prior). People tend to prefer music they are familiar with, and with the huge surge in FM radio's popularity circa the 1960s and 70s came lots of familiarity with the musicians who managed to get radio stations to play their music. This contributed to the rise of hugely popular record labels that dominated the industry and left little room for competition. Today, listeners have more options; there are 1.2 million artists on Spotify alone. This means that getting a song on the radio isn't necessarily enough to bring it the type of success it would have found in decades prior. Nowadays, producers have started to try and boil popular music down to an algorithm; here is an interesting article about how AI is changing the music scene: 
https://www.theverge.com/2018/8/31/17777008/artificial-intelligence-taryn-southern-amper-music

The Times They Are a-Changin', to say the least. But what does this mean for us? Can you really boil music taste, which is seemingly so complex and personal, down to an algorithm? Is there a formula that can produce the perfect song for you? Not yet. However, they are becoming better and better at predicting which songs will appeal to the masses. Today, we are going to look at which features are most closely correlated with the popularity of a song for each of four of the most popular genres; pop, rock, rap, and country. 

This dataset was the ideal choice for conducting this experiment because of both its size and its range. The creator used the Spotify Web API to gather data on "approximately 10,000 [songs] per genre," which is plenty for our purposes. 
The dataset can be found here - https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db 

The R Markdown file can be found here -
https://brelco99.github.io/FINALPROJECT.Rmd

The track properties we will be using today are genre, tempo, duration, and loudness, along with some less quantitative measures like energy, danceability, liveness, valence, acousticness, speechiness, and popularity, calculated by Spotify using their own metrics. 


## The Question: What do listeners want to hear, and how does it vary by genre? 
Can we predict the popularity of a song based on the metrics provided by Spotify? And is this consistent across genres?

## Data Curation
First, we import the song data. For sake of ease, we remove songs with any missing attributes from the dataframe. Then, using the unique track_id of each song, we check for (and remove) duplicate listings. This is the only place we will make use of track_id, so we remove that column from the dataframe. We then remove the time_signature column, leaving us with only attributes that can be normalized in a meaningful manner. Next, we subset to include only the genres of interest, which are country, rock, rap, and pop. Rearranging the dataframe so that char attributes are in the first columns and numeric attributes are in the rest makes it easier to grab either of those subsets when we need to.
```{r, warning=FALSE, message=FALSE}
#Read in data
tunes_tab <- read_csv("ultimate-spotify-tracks-db/SpotifyFeatures.csv")
#Remove any incomplete data
tunes_tab <- na.omit(tunes_tab)
#Remove any duplicate song listings
tunes_tab <- tunes_tab[!duplicated(tunes_tab$track_id),]
#Remove track ID column
tunes_tab$track_id <- NULL
#Remove time signature column (would not produce meaningful correlation coefficient due to discrete nature)
tunes_tab$time_signature <- NULL
#Remove unwanted genres
tunes_tab <- tunes_tab[((tunes_tab$genre == 'Country') | (tunes_tab$genre == 'Rock') |(tunes_tab$genre == 'Rap') |(tunes_tab$genre == 'Pop')),]
#Rearrange dataframe to separate char and double attributes
tunes_tab <- tunes_tab[,c(1, 2, 3, 10, 13, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16)]
#Show a tibble of the new dataframe 
tunes_tab

```
We could also take out the artist and track name variables but it is not necessary just yet.


## Parsing and Data Management

Next, we normalize each of the numeric attributes except for popularity. This will help us determine the correlation between the individual attributes. We can then take a peak at the summary stats for each feature (again, other than popularity).
```{r, warning=FALSE, message=FALSE}
#Normalize the numeric attributes
stand_tunes <- as.data.frame(scale(tunes_tab[7:16]))
#Store the name vars
non_numeric <- tunes_tab[1:6]
#Update tunes_tab with normalized attributes
tunes_tab <- cbind(non_numeric, stand_tunes)
pop_bin <- tunes_tab$popularity
#Bind this new column to the dataframe
tunes_tab <- cbind(tunes_tab, pop_bin)
#View summary data of attributes
summary(stand_tunes)
```


## Exploratory Data Analysis

Now it is time to analyze what we have so far. First, we will look at overall trends with respect to each feature, across all four genres. Check out the ggplot package
https://ggplot2.tidyverse.org/reference/ggplot.html
and the corrplot package 
https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html
to make your plots beautiful.
```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
#Store the feature names to use on plots
feature_names <- names(tunes_tab)[7:16]
plot <- tunes_tab %>%
  select(c(feature_names)) %>%
  #Plot alteration- lengthens columns
  pivot_longer(cols = feature_names) %>%
  #Plot the data and control aesthetics with aes
  ggplot(aes(x = value)) +
  #Used to plot variable density
  geom_density(alpha = 0.5) +
  #Puts multiple similar plots in a smaller area, customizable
  facet_wrap(~name, ncol = 3, scales = 'free') +
  #Label plot
  labs(title = 'Overall Feature Density',
       x = '', y = 'density') +
  dark_theme_gray()
#Trying to get a dark background for the plot in HTML (not necessary)
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
#Show plot output
plot
```

Next, we are going to spice it up a little by showing how each individual genre contributes to the above curves:
```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
#You know the drill
feature_names <- names(tunes_tab)[7:16]
plot <- tunes_tab %>%
  select(c('genre', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value)) +
  geom_density(aes(color = genre), alpha = 0.5) +
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Feature Density by Genre',
       x = '', y = 'density') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```
Much prettier. Now, looking at these graphs, we can see a few of the distinct features of each genre. Only a few trends stand out in particular in this visual. Rap tends to score lower on energy and slightly lower on valence than the other three, but also tends to be rated as more danceable. Country music tends to be the most neutral in terms of danceability of the group. Another way to look at this data (arguably the easier-to-read way) is by using a correlation plot (you'll need the ggcorrplot package to use this function in particular, helpful info on that here -> http://www.sthda.com/english/wiki/ggcorrplot-visualization-of-a-correlation-matrix-using-ggplot2):
```{r, fig.width=10, fig.height=8, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[6:16]
plot <- tunes_tab %>%
  select(feature_names) %>%
  #Scales the original popularity variable for this purpose
  scale() %>%
  #Calculates correlation
  cor() %>%
  #Plots correlation- lower half of triangle, ordered by correlation coefficient to some extent
   ggcorrplot(type = "lower", hc.order = TRUE,
         col = brewer.pal(n = 2, name = "RdBu"))  + dark_theme_gray() 
plot + theme(axis.text.x = element_text(angle = 90, hjust = 1),
             rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(colour = "#222222"),axis.title.x = element_blank(), axis.title.y = element_blank())



```

This lets us see a simpler representation of the correlations. There is unfortunately not a lot of very strong correlation. However, we can see from this plot that there is a relatively strong positive correlation between energy and loudness, and a relatively strong negative correlation between acousticness and both energy and loudness. Energy, loudness, danceability, and valence are all positively correlated, while instrumentalness is negatively correlated with energy and loudness. Popularity is most strongly correlated with energy, loudness, and danceability. Interesting! 

We can plot the relationships between popularity and danceability, energy, and loudness:

```{r, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}
feature_names <- names(tunes_tab)[c(8, 10, 13)]
plot <- tunes_tab %>%
  select(c('genre', 'popularity', feature_names)) %>%
  pivot_longer(cols = feature_names) %>%
  ggplot(aes(x = value, y=popularity, color = genre)) +
  geom_smooth( alpha = 0.5, se = FALSE)+
  facet_wrap(~name, ncol = 3, scales = 'free') +
  labs(title = 'Danceability, Energy, and Loudness vs Popularity',
       x = '', y = 'Popularity') +
  dark_theme_gray()
plot <- plot +
  theme(
     rect = element_rect(fill = "#222222"), # all rectangles
     panel.grid.major = element_line(color = "#222222"),
    
  ) 
plot
```

We can see here that increased danceability tends to increase popularity for rap, pop, and rock songs, but not country songs. Increasing energy tends to decrease popularity for rock songs, but only very slightly. There is not much of a relationship between energy and the other genres. Finally, as loudness increases, pop popularity increases notably, country popularity increases slightly, and the other two do not change much in either direction. It is clear that the genres each have distinct features that correlate with popularity (although country music has the weakest correlations of the lot).

Now that we know that each genre has different features correlating with its popularity index, we can see which ones and to what scale through the use of random forest modeling.


## Hypothesis Testing and Machine Learning

Finally, it is time to build the model. Can we predict which songs will be rated with a popularity score of 70 or above for each genre, simply by feature analysis? Let's see:



First, we read all of the data for one genre into the song_features dataframe. This is a function so we can reuse it for modeling the other genres. Pass in the genre of interest and receive a dataframe with 12 numeric variables in return. It is a good idea to try and omit empty entries whenever you are subsetting data, so we make sure to do that as well. 
```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
features_by_genre <- function(genre) {
genre_data <- tunes_tab[tunes_tab$genre == genre,]
song_features <- genre_data %>%
  select(
    popularity,
    pop_bin,
    acousticness,
    danceability,
    duration_ms,
    energy,
    instrumentalness,
    liveness,
    loudness,
    speechiness,
    tempo,
    valence
  ) %>% 
  na.omit()
song_features
}
```

Now we have our dataframe. We will start by creating a random forest model for predicting rap song popularity outcomes. The tutorial will mostly walk through the rap section and the process will be repeated for each other genre, with output displayed but code chunks not included to avoid redundancy. 
Here are links to two sites I found useful for random forest information:
https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/
https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/tutorial-random-forest-parameter-tuning-r/tutorial/

### Rap 
Here, we call the above function to get our rap-only dataframe. Then we plan to use pop_bin, which was previously a copy of popularity and varied substantially between genres, so we scale it to each one individually. We turn pop_bin into a column of 0s and 1s, depending on whether or not the songs are in the top 25% most popular songs of the genre in the dataset. Finally, we select pop_bin as our factor for the model.
```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE}
#Pull out genre data
song_features <- features_by_genre('Rap')
#Scale popularity to individual genre
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
#Input 0 or 1 to factor column depending on popularity
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
#Select pop_bin as factor
song_features$pop_bin <-as.factor(song_features$pop_bin)
#Remove original popularity column
song_features$popularity = NULL
```


Now, we select our sample data. We need one set of data, train_set, to be used to train the random forest model how to interpret the data. The valid_set is used to compare to results from the trained model. 
```{r, warning=FALSE, message=FALSE}
#Keeps your "random" samples consistent
set.seed(1234)
#Draw sample 
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
#Split sample between training data and data for future comparison
train_set <- as.data.frame(song_features[train,])
valid_set <- as.data.frame(song_features[-train,])
```


Now we create the model. There are many, many options when it comes to designing your random forest model, but for today's purposes we will leave several of the options to default. There are several ways to tune the parameters of your random forest model to get the best predictions. One way is to test which mtry value (number of variables randomly sampled at each split) results in the smallest error. I have already done this for each of the models and set the mtry option accordingly, but that code chunk in particular was very slow to run, so I will include the line I used as text:

bestmtry <- tuneRF(song_features[,-10], song_features[,10], stepFactor=1.5, improve=1e-5, ntree=500)

```{r, warning=FALSE, message=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 2, ntree = 500)
model
```

We can see that the rate of error was 20.61%, which is not terrible. The model has a bad false negative rate but a solid true negative rate. Now we can take a deeper look into the results using the importance() function.
```{r, warning=FALSE, message=FALSE}
importance(model)
```

Based on this, we can see that popularity in rap music is most strongly associated with lower energy, and to a lesser extent lower loudness and speechiness. 

```{r, warning=FALSE, message=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```
Again, we can see that the model is much better at predicting negatives than positives, which makes sense given that the makeup up the original dataset is full of unpopular songs (there are less popular songs out there). Next, we have rock music.

### Rock

-Grab data for rock genre
```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE, echo=FALSE}
song_features <- features_by_genre('Rock')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```

-Select sample data and subset for training
```{r, warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```

-Create model, tuning parameters as you feel fit
```{r, warning=FALSE, message=FALSE, echo=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 4, ntree = 500)
model
```

-Display importance stats
```{r, warning=FALSE, message=FALSE, echo=FALSE}
importance(model)
```
-Finally, check accuracy of prediction using the model
```{r, warning=FALSE, message=FALSE, echo=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```
Again, best at predicting true negatives. 

Rinse and repeat.

### Country

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE, echo=FALSE}
song_features <- features_by_genre('Country')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 3, ntree = 500)
model
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```


### Pop

```{r, warning=FALSE, message=FALSE, stringsAsFactors = FALSE, echo=FALSE}
song_features <- features_by_genre('Pop')
song_features$pop_bin <- as.data.frame(scale(song_features[1]))
song_features$pop_bin <- ifelse((song_features$pop_bin >= .675), 1, 0) 
song_features$pop_bin <-as.factor(song_features$pop_bin)
song_features$popularity = NULL
```


```{r, warning=FALSE, message=FALSE, echo=FALSE}
set.seed(1234)
train <- sample(nrow(song_features), 0.7*nrow(song_features), replace = FALSE)
train_set <- song_features[train,]
valid_set <- song_features[-train,]
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
model  <- randomForest(pop_bin ~ ., data = train_set, importance = TRUE, type = classification, mtry = 3, ntree = 500)
model
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
importance(model)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
predictions <- predict(model, newdata = valid_set)
table(predictions, valid_set$pop_bin)
```

## Insights

The model had a similar error rate in predicting popularity all four genres; the pop model had an error rate of 20.82%, the country model 19.27%, the rock model 23.3%, and the rap model 20.61%. This is decent performance, given that the random forest function was used with mostly default settings and we did not go great lengths to tune hyperparameters/optimize the model. We can see that dancibility, loudness, and energy are the most reliable indicators of popularity for pop songs; energy, speechiness, and loudness were the best indicators for country songs; energy, loudness, and valence for rock were the best indicators for rock songs; and energy, loudness, and speechiness are the most reliable indicators for rap songs. 
This experiment demonstrates that there is definitely potential in the field of optimizing song popularity outcomes by tuning individual features to special standards for each genre. Maybe in the next couple of years, Spotify will produce a song catered to your personal feature preferences. Or maybe they will start to make music so perfect in terms of feature harmony that all music tastes will converge. Regardless of the outcome, the future is upon us. Thanks for reading! 








